{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmukul-potta\u001b[0m (\u001b[33mmukul-potta-indian-institute-of-technology-gandhinagar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/preyum.kumar/CollegeWork/computer vision/wandb/run-20241114_214637-nsa4oczx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mukul-potta-indian-institute-of-technology-gandhinagar/uncategorized/runs/nsa4oczx' target=\"_blank\">cerulean-sky-1</a></strong> to <a href='https://wandb.ai/mukul-potta-indian-institute-of-technology-gandhinagar/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mukul-potta-indian-institute-of-technology-gandhinagar/uncategorized' target=\"_blank\">https://wandb.ai/mukul-potta-indian-institute-of-technology-gandhinagar/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mukul-potta-indian-institute-of-technology-gandhinagar/uncategorized/runs/nsa4oczx' target=\"_blank\">https://wandb.ai/mukul-potta-indian-institute-of-technology-gandhinagar/uncategorized/runs/nsa4oczx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-final_MCB:v31, 290.05MB. 5 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('mukul-potta-indian-institute-of-technology-gandhinagar/marathi_nlp/model-final_MCB:v31', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import LlamaConfig, LlamaForCausalLM, AutoTokenizer, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./Tokenizer3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LlamaConfig(hidden_size=256,\n",
    "                     vocab_size=len(tokenizer.vocab),\n",
    "                     num_attention_heads=4,\n",
    "                     num_key_value_heads=2,\n",
    "                     num_hidden_layers=12,\n",
    "                     intermediate_size=688,\n",
    "                     eos_token_id = 2,\n",
    "                     bos_token_id = 1,\n",
    "                     max_position_embeddings=64)\n",
    "\n",
    "model_mis = LlamaForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128000, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (down_proj): Linear(in_features=512, out_features=256, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((256,), eps=1e-06)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((256,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((256,), eps=1e-06)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=128000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mis.from_pretrained(\"./artifacts/model-final_MCB:v31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1907052/2285945722.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model_mis, tokenizer=tokenizer)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model_mis, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पोटनिवडणुक मोहक मोहक मोहक मोहक मोहक मोहक मोहक जमिनीच्या जमिनीच्या जमिनीच्या जमिनीच्या जमिनीच्या जमिनीच्या जमिनीच्या\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "स्कर्ट स्कर्ट स्कर्ट स्कर्ट सोमी सोमी सोमी सोमी सोमी सोमी सोमी\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "कुरेशी कुरेशी प्रश्नाच्या कुरेशी प्रश्नाच्या प्रश्नाच्या प्रश्नाच्या प्रश्नाच्या\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "घालवल्यानंतर घालवल्यानंतर एक्झॉस्ट बंगळुरु चतुरंग ठाकुर, ठाकुर, ठाकुर, ठाकुर, ठाकुर, ठाकुर, ब्रार ठाकुर, ठाकुर, शोधणे, शोधणे, ब्रार ठाकुर, ठाकुर, ठाकुर, शोधणे, ब्रार ब्रार\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "गेमचे (५०दिलीदिलीदिलीदिलीदिलीदिलीदिलीदिलीदिलीदिली\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ांतील रंगावर रंगावर रंगावर रंगावर रंगावर्बी्बी्बी्बी्बी\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "फोब टेम टेम टेम '- '- '- साली '-\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "सहकारात सहकारात सहकारात सहकारात सूत्रांनुसार, तक्रारदारांची सूत्रांनुसार, तक्रारदारांची तक्रारदारांची सूत्रांनुसार, तक्रारदारांची तक्रारदारांची तक्रारदारांचीवरही तक्रारदारांची\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "रोखणे रोखणे रोखणे रोखणे रोखणे रोखणे रोखणे\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "पँट चिखले,ग्नेटिकग्नेटिक मजेशीर इंडस्ट्रीपासून इंडस्ट्रीपासून इंडस्ट्रीपासून इंडस्ट्रीपासून इंडस्ट्रीपासून इंडस्ट्रीपासून\n"
     ]
    }
   ],
   "source": [
    "# Read lines from Prompts.txt\n",
    "with open('Prompts.txt', 'r') as f:\n",
    "    prompts = f.readlines()\n",
    "\n",
    "# Open a new file to write the outputs\n",
    "output_file = open('Prompt_outputs.txt', 'w')\n",
    "\n",
    "for prompt in prompts:\n",
    "    input_dict = {'input_ids': [tokenizer.encode(prompt)]}\n",
    "    custom_dataset = Dataset.from_dict(input_dict)\n",
    "    predictions = trainer.predict(custom_dataset)\n",
    "    generated_outputs = predictions.predictions  # This will be logits\n",
    "    output_ids = torch.argmax(torch.tensor(generated_outputs), dim=2)\n",
    "    output = tokenizer.decode(output_ids[0])\n",
    "    output_file.write(output + '\\n')\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
